#  Лабораторна Робота 4

## 1. Обраний Технологічний Стек

Технологічна архітектура визначає, як саме компоненти системи будуть виконуватися та взаємодіяти на інфраструктурному рівні.

### 1.1. Стек Програмного Забезпечення (Runtime Stack)

| Категорія | Технологія | Обґрунтування Вибору |
| :--- | :--- | :--- |
| **Основна мова** | **Go (Golang)** | Використовується для розробки як **API-Gateway**, так і **Worker-Service**. Go відомий своєю високою продуктивністю та ефективністю у роботі з мережею, що критично для розподілених систем. |
| **Черга/Кеш** | **Redis** | Виконує подвійну роль: **брокер повідомлень** для асинхронності та **кеш** для зберігання статусів завдань (`job_id`). |
| **Сховище файлів** | **Shared Docker Volume** | Спільний файловий простір для обміну зображеннями між контейнерами API та Worker. |

### 1.2. Платформа Розгортання (Deployment Platform)

| Категорія | Технологія | Призначення |
| :--- | :--- | :--- |
| **Контейнеризація** | **Docker** | Упаковка кожного сервісу в ізольоване, переносне середовище, що забезпечує стабільність. |
| **Оркестрація** | **Docker Compose** | Інструмент для визначення, запуску та мережевої взаємодії всіх контейнерів (API, Worker, Redis) у тестовому середовищі. |

---

## 2. Топологія Розгортання (Deployment Topology)

Для опису технологічного забезпечення використовується **Діаграма Розгортання**, яка ілюструє, як контейнеризовані сервіси розміщуються на єдиному Хост-Сервері (що імітує кластер Docker/Kubernetes).

### 2.1. Діаграма Розгортання



### 2.2. Опис Розгортання
1.  **Хост-Сервер:** Єдиний вузол, що виконує Docker Engine.
2.  **Контейнеризація:** Кожен логічний компонент системи (API-Шлюз, Worker, Redis) працює як незалежний контейнер.
3.  **Мережа:** Контейнери API та Worker взаємодіють з Redis через внутрішню мережу Docker.
4.  **Сховище:** **Shared Docker Volume** монтується одночасно в контейнери API та Worker, надаючи спільний простір для читання/запису зображень.

---

## 3. Механізми Забезпечення Стійкості (Fault Tolerance)

Стійкість розподіленої системи забезпечується комбінацією асинхронної взаємодії та механізмів масштабування.

### 3.1. Load Balancer та Replica Sets
* **Load Balancer (Балансувальник Навантаження):** Хоча у Docker Compose його функцію може виконувати єдиний порт API-Шлюзу, в продакшен-архітектурі він необхідний для розподілу вхідних запитів між кількома **репліками** (копіями) **API-Шлюзу**. Це запобігає перевантаженню та забезпечує високу доступність.
* **Replica Sets:** Запуск кількох копій **Worker-Service** дозволяє системі:
    * **Масштабуватися:** Збільшувати пропускну здатність обробки, витягуючи завдання паралельно.
    * **Стійкість:** У разі збою одного Worker-контейнера, інші продовжують обробку.

### 3.2. Стійкість через Асинхронність (Redis Queue)
* **Надійна Черга:** Використання **Redis** як брокера гарантує, що завдання не будуть втрачені, навіть якщо Worker-сервіс тимчасово недоступний. Повідомлення залишається у черзі, поки Worker не відновить роботу і не витягне його.
* **Ідемпотентність:** У реалізації Worker-сервісу необхідно передбачити механізми **ідемпотентності** (запобігання подвійній обробці одного і того ж завдання), оскільки збої можуть призвести до повторної доставки повідомлень.

